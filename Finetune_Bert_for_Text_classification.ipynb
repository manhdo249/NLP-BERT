{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wc4KY-pgKMM0"
      },
      "source": [
        "Bert sử dụng Encoder của Transformer để học mối quan hệ một từ với những từ xung quanh và bổ sung mối quan hệ đó vào vector embedding của từng từ."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DqaZ0TSqVkJz"
      },
      "source": [
        "[Paper Bert](https://arxiv.org/pdf/1810.04805.pdf): BERT: Pre-training of Deep Bidirectional Transformers for\n",
        "Language Understanding"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q tf-models-official\n",
        "!pip install -q -U tensorflow-text\n",
        "# !pip install -q opencv-python"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TsjLzhSJg_rT",
        "outputId": "c93bd045-4277-4ec2-c5e6-4e1de09cca81"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m29.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.7/106.7 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m242.5/242.5 kB\u001b[0m \u001b[31m31.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.2/5.2 MB\u001b[0m \u001b[31m94.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m589.8/589.8 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m88.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.3/5.3 MB\u001b[0m \u001b[31m108.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m98.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m108.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m82.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.2/311.2 kB\u001b[0m \u001b[31m34.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_models as tfm\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow_datasets as tfds\n",
        "tfds.disable_progress_bar()"
      ],
      "metadata": {
        "id": "xJXOOws8jJmk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q0RJ22Fzp6eq",
        "outputId": "70e3840f-333c-4f0d-bf68-e2590ab31bdc"
      },
      "source": [
        "!wget --no-check-certificate \\\n",
        "    https://storage.googleapis.com/learning-datasets/sarcasm.json \\\n",
        "    -O /tmp/sarcasm.json\n",
        "\n",
        "import json\n",
        "\n",
        "with open(\"/tmp/sarcasm.json\", 'r') as f:\n",
        "    datastore = json.load(f)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-05-01 08:58:55--  https://storage.googleapis.com/learning-datasets/sarcasm.json\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 142.251.12.207, 172.217.194.207, 142.250.4.207, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|142.251.12.207|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5643545 (5.4M) [application/json]\n",
            "Saving to: ‘/tmp/sarcasm.json’\n",
            "\n",
            "/tmp/sarcasm.json   100%[===================>]   5.38M  3.98MB/s    in 1.4s    \n",
            "\n",
            "2024-05-01 08:58:57 (3.98 MB/s) - ‘/tmp/sarcasm.json’ saved [5643545/5643545]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_XuCacUJW08q",
        "outputId": "a137166f-c99a-46d2-b177-9bf121e7a01c"
      },
      "source": [
        "datastore[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'article_link': 'https://www.huffingtonpost.com/entry/versace-black-code_us_5861fbefe4b0de3a08f600d5',\n",
              " 'headline': \"former versace store clerk sues over secret 'black code' for minority shoppers\",\n",
              " 'is_sarcastic': 0}"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ekm_LeFrXXjm"
      },
      "source": [
        "dataset = []\n",
        "label_dataset = []\n",
        "\n",
        "for item in datastore:\n",
        "    dataset.append(item[\"headline\"])\n",
        "    label_dataset.append(item[\"is_sarcastic\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-NdzpS3b1085",
        "outputId": "79bce378-f0ed-4831-f682-78ca56f7e172"
      },
      "source": [
        "dataset[:10], label_dataset[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([\"former versace store clerk sues over secret 'black code' for minority shoppers\",\n",
              "  \"the 'roseanne' revival catches up to our thorny political mood, for better and worse\",\n",
              "  \"mom starting to fear son's web series closest thing she will have to grandchild\",\n",
              "  'boehner just wants wife to listen, not come up with alternative debt-reduction ideas',\n",
              "  'j.k. rowling wishes snape happy birthday in the most magical way',\n",
              "  \"advancing the world's women\",\n",
              "  'the fascinating case for eating lab-grown meat',\n",
              "  'this ceo will send your kids to school, if you work for his company',\n",
              "  'top snake handler leaves sinking huckabee campaign',\n",
              "  \"friday's morning email: inside trump's presser for the ages\"],\n",
              " [0, 0, 1, 1, 0, 0, 0, 0, 1, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PUo1Y_sQ5n5J"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "dataset = np.array(dataset)\n",
        "label_dataset = np.array(label_dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hQGv73TT6H3B"
      },
      "source": [
        "train_size = 0.8\n",
        "size = int(len(dataset) * train_size)\n",
        "\n",
        "train_sentence = dataset[:size]\n",
        "test_sentence = dataset[size:]\n",
        "\n",
        "train_label = label_dataset[:size]\n",
        "test_label = label_dataset[size:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JOsaSVay-U9b",
        "outputId": "eed0fdf5-6361-406b-aacf-a0635232dbde"
      },
      "source": [
        "len(train_sentence), len(test_sentence)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(21367, 5342)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_models as tfm\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow_datasets as tfds\n",
        "tfds.disable_progress_bar()"
      ],
      "metadata": {
        "id": "xjJD-LQmhzjP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y0h0YXc6SGCI",
        "outputId": "1eaee3bc-4dd3-450a-b600-32d90349e1aa"
      },
      "source": [
        "gs_folder_bert = \"gs://cloud-tpu-checkpoints/bert/v3/uncased_L-12_H-768_A-12\"\n",
        "tf.io.gfile.listdir(gs_folder_bert)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['bert_config.json',\n",
              " 'bert_model.ckpt.data-00000-of-00001',\n",
              " 'bert_model.ckpt.index',\n",
              " 'vocab.txt']"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "14xDolWVSKim"
      },
      "source": [
        "hub_url_bert = \"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/3\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x2lYCw_ZSMQv"
      },
      "source": [
        "tokenizer = tfm.nlp.layers.FastWordpieceBertTokenizer(\n",
        "    vocab_file=os.path.join(gs_folder_bert, \"vocab.txt\"),\n",
        "    lower_case=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokens = tokenizer(tf.constant([\"Hello TensorFlow!\"]))\n",
        "tokens"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nq78nHXLlG4u",
        "outputId": "dfd0d5a7-1df7-4280-f224-2c28d2c33718"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[[7592], [23435, 12314], [999]]]>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "special = tokenizer.get_special_tokens_dict()\n",
        "special"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Yx_z3W-lNzF",
        "outputId": "9d3a1608-bc7d-4c5b-8ca7-78ad7b1375aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'vocab_size': 30522,\n",
              " 'start_of_sequence_id': 101,\n",
              " 'end_of_segment_id': 102,\n",
              " 'padding_id': 0,\n",
              " 'mask_id': 103}"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_seq_length = 128\n",
        "\n",
        "packer = tfm.nlp.layers.BertPackInputs(\n",
        "    seq_length=max_seq_length,\n",
        "    special_tokens_dict = tokenizer.get_special_tokens_dict())"
      ],
      "metadata": {
        "id": "HJGLK4b-biFo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentences1 = [\"hello tensorflow\"]\n",
        "tok1 = tokenizer(sentences1)\n",
        "tok1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AnA7jESzbo0H",
        "outputId": "33c37eab-bea9-4219-a99d-8ec364e31334"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[[7592], [23435, 12314]]]>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentences2 = [\"goodbye tensorflow\"]\n",
        "tok2 = tokenizer(sentences2)\n",
        "tok2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eVlzy8LPboxd",
        "outputId": "153d7b92-48a5-4fe9-fd5a-dffc44c42fd5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[[9119], [23435, 12314]]]>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "packed = packer([tok1, tok2])\n",
        "\n",
        "for key, tensor in packed.items():\n",
        "  print(f\"{key:15s}: {tensor[:, :12]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i0ybSPbibtdl",
        "outputId": "21637dd2-b840-4975-f68e-2424fb59d899"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input_word_ids : [[  101  7592 23435 12314   102  9119 23435 12314   102     0     0     0]]\n",
            "input_mask     : [[1 1 1 1 1 1 1 1 1 0 0 0]]\n",
            "input_type_ids : [[0 0 0 0 0 1 1 1 1 0 0 0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class BertInputProcessor(tf.keras.layers.Layer):\n",
        "  def __init__(self, tokenizer, packer):\n",
        "    super().__init__()\n",
        "    self.tokenizer = tokenizer\n",
        "    self.packer = packer\n",
        "\n",
        "  def call(self, inputs):\n",
        "    tok1 = self.tokenizer(inputs['sentence1'])\n",
        "    tok2 = self.tokenizer(inputs['sentence2'])\n",
        "\n",
        "    packed = self.packer([tok1, tok2])\n",
        "\n",
        "    if 'label' in inputs:\n",
        "      return packed, inputs['label']\n",
        "    else:\n",
        "      return packed"
      ],
      "metadata": {
        "id": "Jt74gJJDb053"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bert_inputs_processor = BertInputProcessor(tokenizer, packer)\n"
      ],
      "metadata": {
        "id": "U-NkBy-Jb3Hu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dTxwTKW8SV5T"
      },
      "source": [
        "tokenizer.convert_tokens_to_ids(['[CLS]', '[SEP]'])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "44IzB6vBS4tq"
      },
      "source": [
        "train_size = 0.8\n",
        "size = int(len(dataset) * train_size)\n",
        "\n",
        "train_sentence = dataset[:size]\n",
        "test_sentence = dataset[size:]\n",
        "\n",
        "train_label = label_dataset[:size]\n",
        "test_label = label_dataset[size:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_sentence"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oDxYBZQxcS7e",
        "outputId": "efb050dc-09d2-4c58-8364-bcaf4e3a65b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([\"former versace store clerk sues over secret 'black code' for minority shoppers\",\n",
              "       \"the 'roseanne' revival catches up to our thorny political mood, for better and worse\",\n",
              "       \"mom starting to fear son's web series closest thing she will have to grandchild\",\n",
              "       ..., 'finding comfort in numbers',\n",
              "       'reporters comb new orleans for heartwarming story',\n",
              "       'actor receives $25 million for everyman role'], dtype='<U254')"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IXDupH9_SnLI"
      },
      "source": [
        "def encode_sentence(s, tokenizer):\n",
        "   tokens = list(tokenizer.tokenize(s))\n",
        "   tokens.append('[SEP]')\n",
        "   return tokenizer.convert_tokens_to_ids(tokens)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer(['[CLS]'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-o2jpIyjdoWc",
        "outputId": "4c44bbb8-0bbc-4e7f-b258-e9f90bffbeab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[[1031], [18856, 2015], [1033]]]>"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xo7utNvfW0mJ"
      },
      "source": [
        "def bert_encode(sentences, tokenizer):\n",
        "  tokenized_sentences = tf.ragged.constant([\n",
        "      encode_sentence(s, tokenizer)\n",
        "      for s in sentences])\n",
        "\n",
        "  # CLS TOken đứng đầu câu\n",
        "  cls = [tokenizer.convert_tokens_to_ids(['[CLS]'])]*tokenized_sentences.shape[0]\n",
        "\n",
        "  input_word_ids = tf.concat([cls, tokenized_sentences], axis=-1)\n",
        "\n",
        "  input_mask = tf.ones_like(input_word_ids).to_tensor()\n",
        "\n",
        "  type_cls = tf.zeros_like(cls)\n",
        "\n",
        "  type_s1 = tf.zeros_like(tokenized_sentences)\n",
        "\n",
        "  input_type_ids = tf.concat(\n",
        "      [type_cls, type_s1], axis=-1).to_tensor()\n",
        "\n",
        "  inputs = {\n",
        "      'input_word_ids': input_word_ids.to_tensor(),\n",
        "      'input_mask': input_mask,\n",
        "      'input_type_ids': input_type_ids}\n",
        "\n",
        "  return inputs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JkkSWCFCT7SX"
      },
      "source": [
        "train_inputs = bert_encode(train_sentence, tokenizer)\n",
        "train_label_tensors = tf.constant(train_label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "88ma0vawUBbi"
      },
      "source": [
        "test_inputs = bert_encode(test_sentence, tokenizer)\n",
        "test_label_tensors = tf.constant(test_label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vTfMI477UItK"
      },
      "source": [
        "import json\n",
        "\n",
        "bert_config_file = os.path.join(gs_folder_bert, \"bert_config.json\")\n",
        "config_dict = json.loads(tf.io.gfile.GFile(bert_config_file).read())\n",
        "\n",
        "bert_config = bert.configs.BertConfig.from_dict(config_dict)\n",
        "\n",
        "config_dict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_h-khbrcUc7q"
      },
      "source": [
        "bert_classifier, bert_encoder = bert.bert_models.classifier_model(\n",
        "    bert_config, num_labels=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h90xtKACUiCt"
      },
      "source": [
        "tf.keras.utils.plot_model(bert_classifier, show_shapes=True, dpi=48)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6B45wvm0Vcc3"
      },
      "source": [
        "test_batch = {key: val[:10] for key, val in train_inputs.items()}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kr0si8BDVlE1"
      },
      "source": [
        "bert_classifier(\n",
        "    test_batch, training=True\n",
        ").numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5pCucnRzV63G"
      },
      "source": [
        "checkpoint = tf.train.Checkpoint(encoder=bert_encoder)\n",
        "checkpoint.read(\n",
        "    os.path.join(gs_folder_bert, 'bert_model.ckpt')).assert_consumed()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jks4KUrhU0Lf"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZlhDlZfTV_H-"
      },
      "source": [
        "# Set up epochs and steps\n",
        "epochs = 3\n",
        "batch_size = 32\n",
        "eval_batch_size = 32\n",
        "\n",
        "train_data_size = len(train_label)\n",
        "steps_per_epoch = int(train_data_size / batch_size)\n",
        "num_train_steps = steps_per_epoch * epochs\n",
        "warmup_steps = int(epochs * train_data_size * 0.1 / batch_size)\n",
        "\n",
        "# creates an optimizer with learning rate schedule\n",
        "optimizer = nlp.optimization.create_optimizer(\n",
        "    2e-5, num_train_steps=num_train_steps, num_warmup_steps=warmup_steps)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kmuc2Qz-WM6-"
      },
      "source": [
        "metrics = [tf.keras.metrics.SparseCategoricalAccuracy('accuracy', dtype=tf.float32)]\n",
        "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "\n",
        "bert_classifier.compile(\n",
        "    optimizer=optimizer,\n",
        "    loss=loss,\n",
        "    metrics=metrics)\n",
        "\n",
        "bert_classifier.fit(\n",
        "      train_inputs, train_label_tensors,\n",
        "      batch_size=32,\n",
        "      validation_data=(test_inputs, test_label_tensors),\n",
        "      epochs=epochs)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}